{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7ad76fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d293f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(): #creating nodes\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None): #initializating\n",
    "        self.feature_index = feature_index #decision node\n",
    "        self.threshold = threshold #decision node\n",
    "        self.left = left #decision node\n",
    "        self.right = right #decision node\n",
    "        self.info_gain = info_gain #decision node\n",
    "        self.value = value #leaf node\n",
    "        \n",
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2): #initializating\n",
    "        self.root = None #root of the tree \n",
    "        self.min_samples_split = min_samples_split # stopping conditions\n",
    "        self.max_depth = max_depth # stopping conditions\n",
    "    def build_tree(self, dataset, current_depth=0): #building tree\n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        samples_numbers, features_numbers = np.shape(X)\n",
    "        if samples_numbers>=self.min_samples_split and current_depth<=self.max_depth: # split until conditions suttisfied\n",
    "            best_split = self.get_best_split(dataset, samples_numbers, features_numbers) # best split\n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                subtree_left = self.build_tree(best_split[\"left_dataset\"], current_depth+1) # recur left\n",
    "                subtree_right = self.build_tree(best_split[\"right_dataset\"], current_depth+1) # recur right\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], # return decision node\n",
    "                            subtree_left, subtree_right, best_split[\"info_gain\"])\n",
    "        leaf_value = self.calculate_leaf_value(Y) # compute leaf node\n",
    "        return Node(value=leaf_value) \n",
    "    def split(self, dataset, feature_index, threshold): #splitting data      \n",
    "        left_dataset = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        right_dataset = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return left_dataset, right_dataset\n",
    "    def get_best_split(self, dataset, samples_numbers, features_numbers): #finding best split\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        for feature_index in range(features_numbers): #all features\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values) \n",
    "            for threshold in possible_thresholds: #present features\n",
    "                left_dataset, right_dataset = self.split(dataset, feature_index, threshold) #current split\n",
    "                if len(left_dataset)>0 and len(right_dataset)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], left_dataset[:, -1], right_dataset[:, -1]\n",
    "                    current_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    if current_info_gain>max_info_gain: # updating best split\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"left_dataset\"] = left_dataset\n",
    "                        best_split[\"right_dataset\"] = right_dataset\n",
    "                        best_split[\"info_gain\"] = current_info_gain\n",
    "                        max_info_gain = current_info_gain\n",
    "        return best_split\n",
    "    def print_tree(self, tree=None, indent=\" \"): #tree output printing\n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "        else:\n",
    "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)    \n",
    "    def information_gain(self, parent, left_child, right_child, mode=\"entropy\"): #computing information    \n",
    "        weight_left = len(left_child) / len(parent)\n",
    "        weight_right = len(right_child) / len(parent)\n",
    "        if mode==\"gini\":\n",
    "            gain = self.gini_index(parent) - (weight_left*self.gini_index(left_child) + weight_right*self.gini_index(right_child))\n",
    "        else:\n",
    "            gain = self.entropy(parent) - (weight_left*self.entropy(left_child) + weight_right*self.entropy(right_child))\n",
    "        return gain\n",
    "    def entropy(self, y): #computing entropy\n",
    "        class_labels = np.unique(y)\n",
    "        entropy = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            entropy += -p_cls * np.log2(p_cls)\n",
    "        return entropy   \n",
    "    def gini_index(self, y): #computing gini index\n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "    def calculate_leaf_value(self, Y): #computing leaf node\n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    def make_prediction(self, x, tree): #making a prediction\n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_value = x[tree.feature_index]\n",
    "        if feature_value<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)\n",
    "    def fit(self, X, Y): #training tree\n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)  \n",
    "    def predict(self, X): #predicting function\n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4b2f3bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "#I used sklearn only for train_test_split, not for tree decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2a34078e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Rank', 'Name', 'Point', 'City', 'Country'], dtype='object')\n",
      "Size:\n",
      "(5250, 6)\n"
     ]
    }
   ],
   "source": [
    "qs_csv = pd.read_csv(\"/home/kali/Desktop/data1.csv\")\n",
    "print(qs_csv.columns)\n",
    "print(\"Size:\")\n",
    "print(qs_csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f0d226f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year       0\n",
       "Rank       0\n",
       "Name       0\n",
       "Point      0\n",
       "City       0\n",
       "Country    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_csv.isnull().sum()\n",
    "qs_csv = qs_csv.dropna() \n",
    "qs_csv.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aed34e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Point</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Harvard University</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>97.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University of Cambridge</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>94.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University of Oxford</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>94.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts Institute of Technology (MIT)</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Johns Hopkins University</th>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>92.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>National Cheng Kung University (NCKU)</th>\n",
       "      <td>2022</td>\n",
       "      <td>346</td>\n",
       "      <td>60.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University of New Mexico</th>\n",
       "      <td>2022</td>\n",
       "      <td>346</td>\n",
       "      <td>60.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Universitas Indonesia</th>\n",
       "      <td>2022</td>\n",
       "      <td>348</td>\n",
       "      <td>60.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aga Khan University</th>\n",
       "      <td>2022</td>\n",
       "      <td>349</td>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northeastern University</th>\n",
       "      <td>2022</td>\n",
       "      <td>349</td>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5029 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Year  Rank  Point\n",
       "Name                                                          \n",
       "Harvard University                           2018     1   97.7\n",
       "University of Cambridge                      2018     2   94.6\n",
       "University of Oxford                         2018     2   94.6\n",
       "Massachusetts Institute of Technology (MIT)  2018     4   92.5\n",
       "Johns Hopkins University                     2018     5   92.1\n",
       "...                                           ...   ...    ...\n",
       "National Cheng Kung University (NCKU)        2022   346   60.7\n",
       "University of New Mexico                     2022   346   60.7\n",
       "Universitas Indonesia                        2022   348   60.6\n",
       "Aga Khan University                          2022   349   60.5\n",
       "Northeastern University                      2022   349   60.5\n",
       "\n",
       "[5029 rows x 3 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_csv_float  = qs_csv.drop(columns=['City', 'Country'], axis=1).set_index('Name') #Only float left\n",
    "qs_csv_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "247d26e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3520, 5)\n",
      "(3520, 1)\n"
     ]
    }
   ],
   "source": [
    "X = qs_csv.iloc[:, :-1].values\n",
    "Y = qs_csv.iloc[:, -1].values.reshape(-1,1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0282ecf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_4 <= Santa Barbara ? 0.010548607815731303\n",
      " left:X_1 <= 24 ? 0.011469684844478856\n",
      "  left:X_4 <= Parkville ? 0.05794519822855837\n",
      "    left:X_2 <= Harvard University ? 0.08763536171884256\n",
      "        left: United States\n",
      "        right: United Kingdom\n",
      "    right: United States\n",
      "  right:X_2 <= University of Wisconsin-Madison ? 0.011360435368795607\n",
      "    left:X_2 <= University of Helsinki ? 0.016183274486490262\n",
      "        left: United States\n",
      "        right: United States\n",
      "    right:X_2 <= Universität Regensburg ? 0.1263087271865767\n",
      "        left: Germany\n",
      "        right: France\n",
      " right:X_4 <= Seoul ? 0.026934224870175494\n",
      "  left:X_4 <= Sendai City ? 0.306748398006408\n",
      "    left:X_4 <= Santiago ? 0.3057094840116279\n",
      "        left: Chile\n",
      "        right: Japan\n",
      "    right: South Korea\n",
      "  right:X_4 <= St. Andrews ? 0.029293485598234525\n",
      "    left:X_2 <= Shanghai Jiao Tong University ? 0.2592045911047346\n",
      "        left: Singapore\n",
      "        right: United Kingdom\n",
      "    right:X_4 <= Taoyuan City ? 0.03450361354047615\n",
      "        left: Taiwan\n",
      "        right: United States\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
    "classifier.fit(X_train,Y_train)\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5092e5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.32471835652750164\n",
      "confusion_matrix:\n",
      " [[  0   0   0 ...   6   0   0]\n",
      " [  0   0   0 ...  64   0   0]\n",
      " [  0   0   0 ...  15   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 346   0   0]\n",
      " [  0   0   0 ...  50   0   0]\n",
      " [  0   0   0 ...  19   0   0]]\n",
      "classification_report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      Argentina       0.00      0.00      0.00         6\n",
      "      Australia       0.00      0.00      0.00        77\n",
      "        Austria       0.00      0.00      0.00        15\n",
      "        Belgium       0.00      0.00      0.00        32\n",
      "         Brazil       0.00      0.00      0.00        24\n",
      "         Canada       0.00      0.00      0.00        63\n",
      "          Chile       1.00      1.00      1.00         9\n",
      " Czech Republic       0.00      0.00      0.00         2\n",
      "        Czechia       0.00      0.00      0.00         1\n",
      "        Denmark       0.00      0.00      0.00        19\n",
      "          Egypt       0.00      0.00      0.00         5\n",
      "        Finland       0.00      0.00      0.00        18\n",
      "         France       0.26      0.57      0.35        46\n",
      "        Germany       0.49      0.14      0.22       125\n",
      "         Greece       0.00      0.00      0.00         9\n",
      "        Hungary       0.00      0.00      0.00         2\n",
      "          India       0.00      0.00      0.00         1\n",
      "      Indonesia       0.00      0.00      0.00         1\n",
      "        Ireland       0.00      0.00      0.00        25\n",
      "         Israel       0.00      0.00      0.00        20\n",
      "          Italy       0.00      0.00      0.00        55\n",
      "          Japan       0.40      0.13      0.20        46\n",
      "        Lebanon       0.00      0.00      0.00         1\n",
      "       Malaysia       0.00      0.00      0.00         3\n",
      "         Mexico       0.00      0.00      0.00         8\n",
      "    Netherlands       0.00      0.00      0.00        47\n",
      "    New Zealand       0.00      0.00      0.00         6\n",
      "         Norway       0.00      0.00      0.00        14\n",
      "       Portugal       0.00      0.00      0.00        11\n",
      "         Russia       0.00      0.00      0.00         3\n",
      "   Saudi Arabia       0.00      0.00      0.00         3\n",
      "      Singapore       0.42      1.00      0.59         8\n",
      "   South Africa       0.00      0.00      0.00        15\n",
      "    South Korea       1.00      0.55      0.71        33\n",
      "          Spain       0.00      0.00      0.00        40\n",
      "         Sweden       0.00      0.00      0.00        42\n",
      "    Switzerland       0.00      0.00      0.00        29\n",
      "         Taiwan       0.24      1.00      0.38        20\n",
      "       Thailand       0.00      0.00      0.00         6\n",
      "         Turkey       0.00      0.00      0.00         7\n",
      " United Kingdom       0.58      0.38      0.46       104\n",
      "  United States       0.30      0.82      0.44       422\n",
      "          China       0.00      0.00      0.00        67\n",
      "      Hong Kong       0.00      0.00      0.00        19\n",
      "\n",
      "       accuracy                           0.32      1509\n",
      "      macro avg       0.11      0.13      0.10      1509\n",
      "   weighted avg       0.22      0.32      0.22      1509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test) \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"accuracy_score:\", accuracy_score(Y_test,Y_pred))\n",
    "print(\"confusion_matrix:\\n\", confusion_matrix(Y_test, Y_pred))\n",
    "print(\"classification_report:\\n\", classification_report(Y_test, Y_pred))\n",
    "# The result is almost similar as was in lab 1 but here it takes a lot of time to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd52edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24445ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
